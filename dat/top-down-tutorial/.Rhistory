data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
i <- which(varnames(jm$mcmc) %in% c(paste0('sigma_beta_national[',1:3,']'),
'beta[2,1]','beta[2,2]',
'beta[1,1]','beta[1,2]'))
traceplot(jm$mcmc[,i])
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
i <- which(varnames(jm$mcmc) %in% c(paste0('sigma_beta_national[',1:3,']'),
'beta[2,1]','beta[2,2]',
'beta[1,1]','beta[1,2]'))
traceplot(jm$mcmc[,i])
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
i <- which(varnames(jm$mcmc) %in% c(paste0('sigma_beta_national[',1:3,']'),
'beta[2,1]','beta[2,2]',
'beta[1,1]','beta[1,2]'))
traceplot(jm$mcmc[,i])
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
traceplot(jm$mcmc[,i])
# initials
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
i <- which(varnames(jm$mcmc) %in% c(paste0('sigma_beta_national[',1:3,']'),
'beta[2,1]','beta[2,2]',
'beta[1,1]','beta[1,2]'))
traceplot(jm$mcmc[,i])
# initials
source(paste0(git_path,'/4_inits.R'))
init <- inits(chains=n.chains, dat=jd)
# Run JAGS
jm <- run.jags(model="C:/RESEARCH/git/wpgp/COD_model_v2/jags_cluster/3_model_3.3.R",
monitor=par.monitor,
data=jd,
n.chains=n.chains,
inits=init,
thin=n.thin,
adapt=n.adapt,
burnin=n.burn,
sample=n.iter,
summarise=F,
#keep.jags.files=TRUE,
method='parallel' #'rjags' #'rjparallel'
)
jm$init <- init
jm$jd <- jd
jm$set.seed <- 123
jm$extend_num <- 0
names.psrf <- varnames(jm$mcmc)[c(grep('mu_beta_national',varnames(jm$mcmc), fixed=T),
grep('sigma_beta_national',varnames(jm$mcmc), fixed=T),
grep('beta[',varnames(jm$mcmc), fixed=T),
grep('alpha[',varnames(jm$mcmc), fixed=T),
grep('sigmaDw[',varnames(jm$mcmc), fixed=T))]
# names.psrf <- varnames(jm$mcmc)[c(grep('Dhat[',varnames(jm$mcmc), fixed=T),
#                                   grep('Nhat[',varnames(jm$mcmc), fixed=T))]
jm$psrf <- gelman.diag(jm$mcmc[,names.psrf], multivariate=F)
max(jm$psrf$psrf[,2])
##
jm$psrf$psrf[jm$psrf$psrf[,2] > 1.1,]
i <- which(varnames(jm$mcmc) %in% c(paste0('sigma_beta_national[',1:3,']'),
'beta[2,1]','beta[2,2]',
'beta[1,1]','beta[1,2]'))
traceplot(jm$mcmc[,i])
# output database
out <- '//worldpop.files.soton.ac.uk/worldpop/Projects/WP517763_GRID3/Working/ZMB/predictions/ZMB_population_v1_0_sql.sql'
# database
out <- '//worldpop.files.soton.ac.uk/worldpop/Projects/WP517763_WOPR_DataRelease/DataReview/ZMB/population/v1.0/ZMB_population_v1_0_sql.sql'
# connect to new database
db <- DBI::dbConnect(RSQLite::SQLite(), file.path(out))
# list fields
DBI::dbListFields(db, 'Nhat')
# list fields
DBI::dbListTables(db)
DBI::dbListFields(db, 'Nhat')
?DBI::dbGetInfo
DBI::dbGetInfo(db)
DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat)')
i <- DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat)')
i <- dbClearResult(DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat)'))
i <- DBI::dbClearResult(DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat)'))
i
DBI::dbClearResult()
DBI::dbClearResult(DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat);'))
DBI::dbSendStatement(db, statement='PRAGMA index_list(NHat);')
DBI::dbSendQuery(db, statement='PRAGMA index_list(NHat);')
print(DBI::dbSendQuery(db, statement='PRAGMA index_list(NHat);'))
i <- DBI::dbSendQuery(db, statement='PRAGMA index_list(NHat);')
print(i)
i <- DBI::dbSendQuery(db, 'PRAGMA index_list(NHat);')
i
i <- DBI::dbSendQuery(db, 'index_list(NHat);')
i <- DBI::dbSendStatement(db, "SELECT type,name,tbl_name,sql FROM sqlite_master WHERE type='index';")
i
# disconnect
DBI::dbDisconnect(db)
out <- '//worldpop.files.soton.ac.uk/worldpop/Projects/WP517763_WOPR_DataRelease/DataFinal/NGA/population/v1.2/NGA_population_v1_2_sql.sql'
# connect to new database
db <- DBI::dbConnect(RSQLite::SQLite(), file.path(out))
DBI::dbListFields(db, 'Nhat')
i <- DBI::dbSendStatement(db, 'PRAGMA index_list(NHat);')
print(i)
i <- DBI::dbSendStatement(db, "SELECT type,name,tbl_name,sql FROM sqlite_master WHERE type='index';")
print(i)
DBI::dbClearResult(db)
DBI::dbClearResult(i)
DBI::dbClearResult(i)
# disconnect
DBI::dbDisconnect(db)
library(wopr)
?woprize
feature <- sf::st_read('c:/RESEARCH/tmp/working/RDC_Zones_de_sante_5prov.shp')
warnings()
getwd()
rm(feature)
ras <- raster::raster('E:/wopr/COD/population/v1.0/COD_population_v1_0_gridded/COD_population_v1_0_gridded.tif')
raster::cellStats(ras, 'sum')
ras <- raster::raster('E:/wopr/COD/population/v1.0/COD_population_v1_0_gridded/COD_population_v1_0_gridded.tif')
raster::cellStats(ras, 'sum')
ras <- raster::raster('E:/wopr/ZMB/population/v1.0/ZMB_population_v1_0_gridded/ZMB_population_v1_0_gridded.tif')
raster::cellStats(ras, 'sum')
pkgbuild::build('c:/RESEARCH/git/wpgp/GHAv1', repo=NULL, type='source')
pkgbuild::build('c:/RESEARCH/git/wpgp/GHAv1')
?package.build
?devtools;:package.build
?devtools::package.build
?devtools::pkgbuild
?pkgbuild::build
getwd()
install.packages('wpgp/GHAv1_0.1.0.tar.gz')
install.packages('wpgp/GHAv1_0.1.0.tar.gz', repo=NULL, type='source')
library(wopr)
woprVision()
.libPaths('c:/research/r/library')
.libPaths()
install.packages('sf')
# load package
library(wopr, lib='c:/research/r/library')
# run app
wopr::woprVision()
citation('wopr')
# load package
library(wopr, lib='c:/research/r/library')
citation('wopr')
shiny::runApp('wpgp/peanutButter/inst/jelly')
# load
library(peanutButter, lib='c:/research/r/library')
# run app
srcdir <- '//worldpop.files.soton.ac.uk/worldpop/Projects/WP517763_GRID3/Working/git/peanutButter'
runApp('wpgp/peanutButter/inst/jelly')
dir.exists(srcdir)
srcdir
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
runApp('wpgp/peanutButter/inst/jelly')
100 / 0
catalogue <- wopr::getCatalogue()
names(catalogue)
head(catalogue)
# load
library(peanutButter, lib='c:/research/r/library')
# run app
srcdir <- '//worldpop.files.soton.ac.uk/worldpop/Projects/WP517763_GRID3/Working/git/peanutButter'
peanutButter::jelly(srcdir)
runApp('wpgp/peanutButter/inst/jelly')
i <- peanutButter:::country_info
library('peanutButter', lib='c:/research/r/library')
i <- peanutButter:::country_info
i$country
install.packages('beepr')
?beepr
?beepr::beepr
beep()
beepr::beep()
beepr::beep()
beepr::beep()
beepr::beep()
?beep
beepr::beep(0)
beepr::beep(0)
beepr::beep(0)
beepr::beep(0)
beepr::beep(0)
beepr::beep(4)
beepr::beep(5)
beepr::beep()
beepr::beep(6)
beepr::beep(7)
beepr::beep(8)
beepr::beep(9)
beepr::beep(10)
beepr::beep(11)
data.frame()
i <- data.frame()
names(i) <- c('a','b','c')
i <- data.frame(matrix(NA, nrow=0, ncol=3))
i
names(i) <- c('a','b','c')
i
class(i)
ncol(i)
i[,'a']
nrow(i)
i[1,'a'] <- 1
i
beepr::beep(8)
catalogue <- wopr::getCatalogue()
wopr::downloadData(catalogue, 'e:/wopr')
# load package
library(wopr, lib='c:/research/r/library')
shiny::runApp('wpgp/wopr/inst/woprVision')
shiny::runApp('wpgp/wopr/inst/woprVision')
wopr:::woprVision_global$version_info
# load package
library(wopr, lib='c:/research/r/library')
runApp('wpgp/wopr/inst/woprVision')
shiny::runApp('wpgp/wopr/inst/woprVision')
# load package
library(wopr, lib='c:/research/r/library')
wopr_dir
rm(wopr_dir)
runApp('wpgp/wopr/inst/woprVision')
hist(rgamma(1e3,1,1))
hist(rgamma(1e3,0.1,0.1))
hist(rgamma(1e3,1,1))
hist(rnorm(1e3,0,1), xlim=c(0,10))
as.numeric('1000L')
1000L
n=1000
nL
as.long(1000)
as.integer(1000)
as.integer(10000)
library(wopr,'c:/research/r/library')
catalogue <- wopr::getCatalogue()
catalogue <- wopr::getCatalogue()
catalogue <- wopr::getCatalogue()
head(catalogue)
?wopr::downloadData
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 100)
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 1000)
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 1000)
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 2000)
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 2000)
wopr::downloadData(dat = catalogue,
wopr_dir = 'E:/wopr',
maxsize = 2000)
x <- sf::st_read('c:/research/tmp/National EAS/National_EAS.shp')
x <- sf::st_read('c:/research/tmp/National EAS/National__EAS.shp')
names(x)
head(x)
sf::st_write(x, 'c:/research/tmp/National EAS/SLE_National_EAS.geojson')
sqrt(5000)
sqrt(10000)
fname <- 'AGO_buildings_v1_1_imagery_year.tif'
fname <- 'e:/research/AGO_buildings_v1_1_imagery_year.tif'
year <- raster::raster(fname)
fname <- 'e:/peanutButter/AGO_buildings_v1_1_imagery_year.tif'
year <- raster::raster(fname)
table(year[])
fname <- 'e:/peanutButter/BDI_buildings_v1_1_imagery_year.tif'
year <- raster::raster(fname)
table(year[])
srcdir <- 'E:/peanutButter'
peanutButter::jelly(srcdir)
# load
library(peanutButter, lib='c:/research/r/library')
srcdir <- 'E:/peanutButter'
peanutButter::jelly(srcdir)
dat = read.csv('out/tab/data.csv', stringsAsFactors=F)
# working directory
setwd(file.path(dirname(rstudioapi::getSourceEditorContext()$path),'../wd'))
names(NA)
NA %in% names(NA)
any(NA %in% names(NA))
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
# cleanup
rm(list=ls()); gc(); cat("\014"); try(dev.off(), silent=T)
# working directory
setwd(file.path(dirname(rstudioapi::getSourceEditorContext()$path),'tutorial'))
dir.create('out', showWarnings=F, recursive=T)
# copy source
file.copy(from = c('../wd/out/master_train.csv','../wd/out/master_predict.csv'),
to = c('master_train.csv','master_predict.csv'),
overwrite = T)
# packages
library(randomForest) # estimating random forest model
# training data from municipalities
master_train <- read.csv(file = "master_train.csv")
head(master_train[,1:5]) # only showing first five columns
# covariates from enumeration areas
master_predict <- read.csv(file = "master_predict.csv")
head(master_predict[,1:4]) # only showing first four columns
dim(master_train)
dim(master_predict)
citation(randomForest)
citation('randomForest')
citation('randomForest')
# cleanup
rm(list=ls()); gc(); cat("\014"); try(dev.off(), silent=T)
setwd(file.path(dirname(rstudioapi::getSourceEditorContext()$path),'tutorial/dat/top-down-tutorial'))
# copy source
file.copy(from = c('../wd/out/master_train.csv','../wd/out/master_predict.csv'),
to = c('master_train.csv','master_predict.csv'),
overwrite = T)
getwd()
# working directory
rd <- dirname(rstudioapi::getSourceEditorContext()$path)
# cleanup
rm(list=ls()); gc(); cat("\014"); try(dev.off(), silent=T)
# working directory
rd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(file.path(rd,'tutorial/dat/top-down-tutorial'))
# copy source
file.copy(from = c(file.path(rd,'wd/out/master_train.csv'),file.path(rd,'wd/out/master_predict.csv')),
to = c('master_train.csv','master_predict.csv'),
overwrite = T)
# packages
library(randomForest) # estimating random forest model
# training data from municipalities
master_train <- read.csv(file = "master_train.csv")
head(master_train[,1:5]) # only showing first five columns
source('C:/RESEARCH/git/wpgp/top-down-tutorial/3. tutorial.R', echo=TRUE)
